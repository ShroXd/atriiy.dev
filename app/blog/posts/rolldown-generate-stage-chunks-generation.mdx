---
title: 'How Rolldown Works: Chunks generation and optimization'
publishedAt: 2025-12-09
tags:
  ['rolldown', 'vite', 'rust', 'chunks']
draft: false
description: ""
---

## JSON Glossary Entries

These work as before, showing content from the JSON file:

- When working with bundlers, you might encounter a [ModuleIdx](abbr:ModuleIdx) in your build output.
- Code splitting can be configured using [match groups](abbr:match_group) to optimize your bundles.

## Markdown Glossary Entries

These are new! They load and render markdown files:

- [React](abbr:React.md) is a popular library for building user interfaces.
- [JavaScript](abbr:JavaScript.md) is the programming language that powers modern web development.

# Introduction

Code generate stage. TODO.

# Generate chunks

Some basic data structure should be introduced before the real content. But we can fold the details, to makes the reader could search them when it's necessary.

```rust
let mut chunk_graph = ChunkGraph::new(self.link_output.module_table.modules.len());
let mut index_splitting_info: IndexSplittingInfo = // BitSet for each module
let mut bits_to_chunk = FxHashMap::with_capacity(self.link_output.entries.len());
let input_base = ArcStr::from(self.get_common_dir_of_all_modules(...));
```


Based on the `self.option.reverse_module`, use different way to handle it.
    - True, generate chunks for each modules
    - False, use algorithm to split the module. We will focus on this whole algorithm

TODO. explain the reverse module logic here, and use following section for the non-reverse module. Basically it includes `init_entry_point` and `split_chunks` functions.

Two main branching strategies.

Path A. preserve modules mode.
Path B. normal bundling mode.

## Path B

Entry point creation. `init_entry_point()`.

### Split chunks

This function essentially transforms the module dependency graph into an efficient chunk allocation strategy. Also apply automatic splitting logic and user-defined code splitting rules.

The split_chunks function includes several steps:
1. entry analysis. `determine_reachable_modules_for_entry` does BFS on the module graph. Starts from each entry, go through all modules. and assign the entry_index to the modules' bits so that we can split the modules to chunks based on this.
2. manual splitting. according to the user-defined groups, which includes pattern matching and function, to split the modules to chunks first. this is because the user has more business information so that make it better than the auto algo.
3. module assignment. group by bts pattern matching. This is a auto algo to makes the chunks not to large, not too small.
4. if its possible, merge and optimize the chunks.


#### Determine reachable modules for entry

When Rolldown performs code splitting, it needs to figure out which modules each entry point can reach. The `determine_reachable_modules_for_entry` function solves this using a breadth-first graph traversal.

The dependencies graph is built during the scan & link stage, the function fetch the dependencies vector via the [module index](abbr:ModuleIdx) on the `link_output.module_table`. The BFS is processed on the module dependency graph via a `VecDeque`, processing modules level by level from the entry point.

For each modules that was scanned, the `entry_index` will be set on its `bits`. This is used for code splitting algorithm, we will discuss it later. All of these information will be stored in the `index_splitting_info`, which is a `IndexVec`. The type defination is `IndexVec<ModuleIdx, SplittingInfo>`. We can use `module_idx` to refer it easily. And the defination of `SplittingInfo` is:

```rust
pub struct SplittingInfo {
  pub bits: BitSet,
  pub share_count: u32,
}
```

This reachability information later determines which modules go into which chunks during the final bundle generation. We will go through the determining process later.

#### Manual code splitting

1. Early exit checks. This is used for extract the code splitting related configrations. Exit the function if there's no configrations.

2. Module group creation phase. 

```rust
let mut name_to_module_groups: FxHashMap<(usize, ArcStr), ModuleGroupIdx>
let mut index_module_groups: IndexVec<ModuleGroupIdx, ModuleGroup>
```

This is a two level data structure design. We get the `match_group_index` and [match group](abbr:match_group.md) from the `match_groups` stored in the `chunking_options`, we use it to create a related index. And the group related data is stored underthe `ModuleGroup` data structure, which can be refered by the index, stored in the `IndexVec`. Such design avoid the inefficient linear seach and also good for sorting after this step.

`name_to_module_group` is a hash map that maps `(match_group_index, group_name)` to `ModuleGroupIdx`. And the related data could be found in the `index_module_groups`, which is used for storing module groups.

```rust
struct ModuleGroup {
  name: ArcStr,
  match_group_index: usize,
  modules: FxHashSet<ModuleIdx>,
  priority: u32,
  sizes: f64,
}
```



3. Module group sorting and filtering.
4. Runtime Module Handling
5. Main processing loop
6. size-based group splitting logic


Handles user-defined code splitting rules (like import() statements)
Assigns modules based on manual splitting configuration
Update `module_to_assigned` tracker

Next, the `apply_manual_code_splitting` is called for running the algorithm. It based on the advanced chunks option from user defined.

Some important things about the `apply_advanced_chunks`.
1. This happens before auto splitting algo. For a fixed project, generate same result.
2. This allows develoepr control content of the generate chunks, put some modules or one module in specific chunks. Helping for performance and CDN, etc.

Get the `match_groups` from the `chunking_options` from `self.options.advanced_chunks`, it has a `test` field, which could be Regex or Function. This is defined in the `enum MatchGroupTest`
Also init `index_module_group` & `name_to_module_group`. Also the core is the `SplittingInfo`, which includes bits and share count.

Then it go through all modules from the `module_table`, and use each matcher to test it.

  - Step 2: apply_advanced_chunks creates chunks for modules matching group
    tests plus size/share filters, optionally pulling deps; it also peels off
    the runtime module into its own chunk. Matched modules are marked assigned so
    theyâ€™re skipped later.
  - Step 3: In the main loop, any unassigned module is either placed into an
    existing chunk if its bitset already maps to a chunk (entry/advanced) or
    queued in pending_common_chunks when optimization is allowed. If optimization
    is disallowed, a new common chunk is created immediately.
  - Step 4: try_insert_common_module_to_exist_chunk tries to merge each pending
    common group into an existing entry chunk when safe (respecting strict entry
    signatures), otherwise makes a new common chunk.

#### Automatic chunk assignment

Assign modules to corresponding chunks
Create shared chunks to store modules that belong to multiple chunks

TODO. explain the `pending_common_chunks`

#### Chunk optimization

try insert common module to exist chunk
optimize facade dynamic entry chunks


#### Algo.

Optimized and configurable chunks' size.

## Post processing phase

1. Merge external import namespaces at chunk level
2. Sort modules within chunks
3. Assign execution order to chunks
4. Create final sorted chunk index vector
5. Find entry-level external modules

## Chunk ordering strategy

1. User-defined entry chunks come first (by index)
2. Other chunks ordered by exec order
3. Entry chunks before common chunks when exec order are equal

-----

Summary of Rolldown's Code Splitting Algorithm

**Entry Points and Discovery**: Rolldown starts with user-defined entry points from your config, but automatically discovers additional "virtual" entry points from dynamic imports (`import()` statements) in your code. Each entry point gets assigned a unique bit position (0, 1, 2, etc.).

**BitSet Reachability Analysis**: The algorithm performs a depth-first traversal from each entry point, marking every reachable module with that entry's bit. Each module accumulates a BitSet representing which entry points can reach it - for example, a module reachable from entries 0 and 2 would have BitSet `101`.

**Pattern-Based Chunking**: Modules with identical BitSets (same reachability patterns) are grouped into the same chunk. The algorithm maintains a `bits_to_chunk` HashMap that maps each unique BitSet pattern to a chunk, enabling perfect deduplication.

**Manual Code Splitting Integration**: Before the automatic BitSet-based splitting runs, rolldown applies user-defined manual code splitting rules using pattern matching (regex) or functions. Modules captured by manual rules are marked as assigned and excluded from automatic splitting.

**Optimal Chunk Creation**: The final result is mathematically optimal chunking where shared dependencies automatically become common chunks, entry-specific code stays separate, and modules with identical usage patterns are co-located for optimal caching and loading performance.

**Real-World Benefits**: This approach delivers faster initial loads (users download only what they need), better caching (shared code cached once), and near-instant subsequent navigation - all with minimal configuration since the algorithm discovers optimal boundaries from your actual code structure.
